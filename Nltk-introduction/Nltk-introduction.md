1. Tokenizing

Website www.technopedia.com claims that:

"Tokenization is the act of breaking up a sequence of strings into pieces such as words, keywords, phrases, symbols and other elements called tokens. 
Tokens can be individual words, phrases or even whole sentences. In the process of tokenization, some characters like punctuation marks are discarded. 
The tokens become the input for another process like parsing and text mining. Tokenization is used in computer science, where it plays a large part in the process of lexical analysis."

tokenizing script is breaking up a simple quote from Wittgenstein into pieces.


2. Stop words

As searchmicroservices.techtarget.com says: 

"In computer search engines, a stop word is a commonly used word (such as "the") 
that a search engine has been programmed to ignore, both when indexing entries for searching 
and when retrieving them as the result of a search query."

stop_words script is trying to get ridd of it, with simple program. Example is another quote from Wittgenstein.


3. Stemming

From we know that:

"Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. 
Stemming is important in natural language understanding (NLU) and natural language processing (NLP).
Stemming is a part of linguistic studies in morphology and artificial intelligence (AI) information retrieval and extraction. 
Stemming and AI knowledge extract meaningful information from vast sources like big data or the Internet since additional forms of a word related to a subject may need to be searched to get the best results. 
Stemming is also a part of queries and Internet search engines."

stemming script first do stemming on three simple words, and then with one more quote from Wittgenstein. It is easy to spot that
stemming of Wittgenstein quote is far from excellence. 


4. Part of speech tagging

On www.medium.com we can read that:

"POS tagging is the process of marking up a word in a corpus to a corresponding part of a speech tag, based on its context and definition."

part_of_speach_tagging is more complexed script, using PunktSentenceTokenizer, guttenberg corpus and Walt Whitman's "The leaves" as training sample.

5. Chunking

As www.thoughtco.com says that "In studies of language acquisition, the term chunk refers to several words 
that are customarily used together in a fixed expression, such as "in my opinion," "to make a long story short," "How are you?" or "Know what I mean?". 
Also known as language chunk, lexical chunk, praxon, formulated speech, formulaic phrase, formulaic speech, lexical bundle, lexical phrase, and collocation."

chunking is even more complexed script, that do chunking of two quotes from Allen Ginsberg and draws diagrams to describe it.










